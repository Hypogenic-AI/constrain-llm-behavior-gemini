def calculate_inconsistency_score(greedy_answer, sampled_answers):
    """
    Calculates an inconsistency score based on token overlap (1 - IoU).
    Higher score = Higher Inconsistency (Likely Hallucination/Uncertainty).
    
    Args:
        greedy_answer (str): The main answer generated by the model.
        sampled_answers (list[str]): A list of stochastically generated answers.
        
    Returns:
        float: A score between 0.0 (consistent) and 1.0 (inconsistent).
    """
    if not greedy_answer:
        return 1.0 # Empty answer is suspicious/uncertain

    greedy_tokens = set(greedy_answer.lower().split())
    if not greedy_tokens:
        return 1.0
        
    overlaps = []
    for sample in sampled_answers:
        sample_tokens = set(sample.lower().split())
        if not sample_tokens:
            overlaps.append(0.0)
            continue
        intersection = greedy_tokens.intersection(sample_tokens)
        union = greedy_tokens.union(sample_tokens)
        iou = len(intersection) / len(union) if union else 0.0
        overlaps.append(iou)
    
    if not overlaps:
        return 0.0 # No samples provided
        
    avg_overlap = sum(overlaps) / len(overlaps)
    score = 1.0 - avg_overlap 
    return score
